{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processando Vazao_estacao_40800001.json...\n",
      "‚úÖ CSV salvo em C:\\Projetos\\SistemaHidrologico\\src\\hidrologia_estatistica\\sistema_hidrologico\\Arquivos Apresentacao\\Processado\\Vazao_estacao_40800001.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DOWNLOAD DADOS\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Caminho absoluto at√© a pasta \"src\"\n",
    "sys.path.append(r\"C:\\Projetos\\SistemaHidrologico\\src\")\n",
    "\n",
    "# Agora o import funciona corretamente\n",
    "from banco_dados_hidrologicos.sistema_hidrologico.ANA.ANA_Swagger_Processamento import *\n",
    "\n",
    "Processer = Processamento_JSON()\n",
    "df = Processer.P_HidroSerieVazao(\n",
    "    pasta_json=r\"C:\\Projetos\\SistemaHidrologico\\src\\hidrologia_estatistica\\sistema_hidrologico\\Arquivos Apresentacao\\Bruto\",\n",
    "    pasta_saida_csv=r\"C:\\Projetos\\SistemaHidrologico\\src\\hidrologia_estatistica\\sistema_hidrologico\\Arquivos Apresentacao\\Processado\"\n",
    ")\n",
    "\n",
    "# Supondo que seu DataFrame se chama df\n",
    "# Ordenamos pelo n√≠vel de consist√™ncia (maior primeiro) e depois removemos duplicatas de datas\n",
    "df = df.sort_values('Nivel_Consistencia', ascending=False)\\\n",
    "       .drop_duplicates(subset='Data', keep='first')\\\n",
    "       .sort_values('Data', ascending=True)\\\n",
    "       .reset_index(drop=True)\n",
    "\n",
    "# Mant√©m apenas as duas primeiras colunas: Data e Valores\n",
    "df = df.iloc[:, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecaputo\\AppData\\Local\\Temp\\ipykernel_31704\\790977003.py:7: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  annual_maxima = df[df.columns[0]].resample('A').max()\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Selecionando os m√°ximos anuais (no exemplo, vaz√£o)\n",
    "'''\n",
    "\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "df.set_index('Data', inplace=True)\n",
    "annual_maxima = df[df.columns[0]].resample('A').max()\n",
    "xs = annual_maxima.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 377.5375,  572.9363,  468.4064,  307.1106,  470.7589,  672.7476,\n",
       "        334.2575,  345.2491,  306.0348,  479.498 ,  650.    ,  781.    ,\n",
       "        328.9816,  711.0194,  404.7061,  252.2584,  289.9942,  621.3901,\n",
       "        677.3868,  301.5918,  218.8065,  367.7112,  393.941 ,  793.6881,\n",
       "        481.9305,  236.4827,  739.3044,  544.4062,  710.5218,  456.8973,\n",
       "        439.9024,  302.5826,  325.4749,  513.5925,  403.3785,  430.0981,\n",
       "        337.0503,  332.41  ,  277.6914,  543.2256,  753.6222,  833.7053,\n",
       "        536.3968,  326.2911,  532.0909,  586.3079,  348.5581,  944.2283,\n",
       "        467.6254,  398.3744,  487.0101,  427.1316,  282.7122,  763.9771,\n",
       "        706.5582,  386.3359,  544.817 ,  584.6284,  479.4352, 2193.8413,\n",
       "        264.7141,  345.2491,  433.4188,  420.7345,  348.7363,  454.6789,\n",
       "        566.8115,  526.739 ,  268.5586,  398.379 , 1958.6655,  520.7216,\n",
       "        312.5012,  695.6575, 1162.4102,  289.9942,  235.8499,  314.663 ,\n",
       "        496.7983,  387.6794,  249.1643,  299.0753,  779.2241,  266.6135,\n",
       "       1029.5236,  670.8592])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hidrologia_estatistica.sistema_hidrologico.MetodosEstatisticos import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel = Gumbel()\n",
    "weibull = Weibull()\n",
    "gumbel_min = GumbelMin()\n",
    "weibull_max = Weibull_Max()\n",
    "gev = GEV()\n",
    "normal = Normal()\n",
    "#Gama = Gama()\n",
    "Exponencial = Exponential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loc': 407.01976894278187, 'scale': 166.2307387090229}\n",
      "{'loc': 0, 'scale': 585.9867938506356, 'c': 1.843265164429702}\n",
      "{'loc': -707.6811564847346, 'scale': 530.7043740902711}\n",
      "{'loc': 0, 'scale': 1.2325951644071314e-33, 'c': 1.499999999999993}\n",
      "{'loc': 133.8322358227611, 'scale': 378.3202431536504, 'c': -0.3424059681910763}\n",
      "{'loc': 517.2445244186047, 'scale': 307.38249310493376}\n",
      "{'loc': 218.8065, 'scale': 298.43802441860464}\n"
     ]
    }
   ],
   "source": [
    "metodo = 'mvs'\n",
    "\n",
    "\n",
    "gumbel.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(gumbel.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "weibull.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(weibull.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "gumbel_min.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(gumbel_min.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "weibull_max.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(weibull_max.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "gev.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(gev.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "normal.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(normal.scipy_params)     # mostra os par√¢metros ajustados\n",
    "\n",
    "Exponencial.fit(xs, method=metodo)   # ajusta os dados pelo m√©todo dos momentos\n",
    "print(Exponencial.scipy_params)     # mostra os par√¢metros ajustados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc = 707.6811564847346\n",
      "scale = 530.7043740902711\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "loc, scale = stats.gumbel_l.fit(xs)\n",
    "\n",
    "print(\"loc =\", loc)\n",
    "print(\"scale =\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.lmoms_name == 'wei':\n",
    "            params = self.distribuition.fit(self.fit_to, floc = 0)\n",
    "        else:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meu_ambiente",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
